# Lab3 : Straight Lane Detection and Departure Warning

Date : 2023_March_1

Author : Lee Chan Keun 21900575

Github : [https://github.com/lcg0070/DLIP/tree/main/lab3](https://github.com/lcg0070/DLIP/tree/main/lab3)

Demo Video : [https://www.youtube.com/watch?v=qXyMKnjdfbg&ab_channel=학부생](https://www.youtube.com/watch?v=qXyMKnjdfbg&ab_channel=%ED%95%99%EB%B6%80%EC%83%9D)

# Introduction

This lab is required to create a simple program that displays lane departure warning messages from road lane detection. Only the straight lanes are to be detected and other difficult driving environments such as curved lanes and road intersections are ignored. The evaluation of the project will be based on the success detection rate of the lanes of the test and validation video clips.

**Goal :** Determine the degree of lateral bias and direction of lane changes of the input video. And print the output on the screen

# Preparation

**Software Installation**

- OpenCV 3.4.2, Visual Studio Code 1.77.3

**Dataset**

Video of a car being driven

video link : [https://drive.google.com/file/d/13ZiuL3sDKcptWPdPC_KzsUNcWIStWpWl/view](https://drive.google.com/file/d/13ZiuL3sDKcptWPdPC_KzsUNcWIStWpWl/view)

[https://drive.google.com/file/d/1eO_fmHNfhX0FEU1rtiVpZxfOJEoksSLf/view](https://drive.google.com/file/d/1eO_fmHNfhX0FEU1rtiVpZxfOJEoksSLf/view)

# Algorithm

## Overview

![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/Flowchart.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/Flowchart.png)

## Procedure

### Image Processing

- Read the video by frame, and convert it into a photo.
- Below is a frame that was converted to grayscale and canny was used. This photo shows that using canny without the preprocessing process of the image causes a lot of noise in the frame, making it difficult to detect lines

![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/cvtGray.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/cvtGray.png)

1. **Filtering**
- Blur had to be used to reduce noise. I wanted a picture as close to the original as possible, so I used the Gaussian blur. Kenerl Size is 7 because l  experimentally found that this kernel size is a size that removes noise well and preserves the original picture well
    
    ![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/gaussianblur.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/gaussianblur.png)
    
1. **Canny**
- On average, vehicle lines are well detected, but relatively short lines are detected while the vehicle is changing lanes. Therefore, the minimum threshold value was set to 50, so that the lines could be fully detected.
1. **ROI**
- Since the information we want are lanes, I set the ROI based on the vertices below and the middle point of the screen. And created a new processed image to use as a variable

![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/roi_canny.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/roi_canny.png)

```python
vertices = np.array([[(0+100, height-70), (width / 2, height / 2+50), (width-100, height-70)]], dtype=np.int32)
mask = np.zeros_like(processed_img)
cv.fillPoly(mask, vertices, 255)
roi_img = cv.bitwise_and(processed_img, mask)
```

### Determine Lane

1. **HoughLinesP**
    - The HoughLines function returns rho and theta. Theta has a value between 0 and 180 when calculated as an degree, but rho can have both positive and negative numbers. Therefore, it is necessary to pay more attention to situations in which similar lines but completely different values of rho and theta may come out depending on whether they pass above the point(0,0), and it is more difficult to express coordinates using trigonometric functions when calculating coordinates.
    
          +)The rho and theta values of line1 and line2 are completely different
    
    ![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/HoughLines.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/HoughLines.png)
    
    - So, I wrote the code using the simpler expression HoughLinesP
    
    ```python
    lines = cv.HoughLinesP(roi_img, 1, np.pi / 180, 50, minLineLength=50, maxLineGap=5)
    ```
    

1. **Calculating slopes of lines**
    - Made a function to find the slope. In order to prevent the situation of being divided by 0, a very small value was added to the dividing value.
    
    ```python
    get_slope = lambda x1, y1, x2, y2: (y2 - y1) / (x2 - x1 + 1e-6)
    ```
    
    - The position of the lane was determined by the slope. When calculating the angle with degree, the slope of left lane is from -tan (60) to -tan (30), the right lane is from tan (30) to tan (60). And if absolute slope value is greater than tan (60), it is center lane which is only detected when changing lanes
    - Many lines that meet the criteria are detected. However, there is a large error in making it a single line with the average slope of the detected lines. Therefore, the x, y coordinates and slopes were stored based on the line with the largest (longest) y coordinate difference between the two points among the detected lines
    
    ```python
    def cal_lines(lines):
        x_left,x_right,x_center,y_left,y_right,y_center=0,0,0,0,0,0
        max_left, max_right, max_cen= 0,0,0
        slope_right, slope_left, slope_center = 0,0,0
        for line in lines:
            x1, y1, x2, y2 = line[0]
            slope = get_slope(x1, y1, x2, y2)
            if slope < np.tan(deg2Rad(60)) and slope> np.tan(deg2Rad(30)):
                if(abs(y1-y2)>max_right):
                    x_right=x1
                    y_right=y1
                    slope_right = slope
                    max_right = abs(y1-y2)
            elif slope < -np.tan(deg2Rad(30)) and slope> -np.tan(deg2Rad(60)):
                if(abs(y1-y2)>max_left):
                    x_left=x1
                    y_left=y1
                    slope_left = slope
                    max_left = abs(y1-y2)
            elif abs(slope) >= np.tan(deg2Rad(60)):
                if(abs(y1-y2)>max_cen):
                    x_center=x1
                    y_center=y1
                    slope_center = slope
                    max_cen = abs(y1-y2)
            left = [int(x_left),int(y_left),slope_left]
            center = [int(x_center),int(y_center),slope_center]
            right =[int(x_right),int(y_right),slope_right]
        return left, center, right
    ```
    

1. **Determine lanechange**
    - Declared a boolean type variable named linecange
    If the slope of the center lane was detected, the lane would be changing. Therefore, I made linecange true and the rest false
    But, in the case of lanes, continuous lines may appear, but in the case of dotted lines, so even if the center lane is not detected, the lane may be being changed. Therefore, it was set to false when both left and right lane were detected.
    - In addition, each x, y coordinate and slope were stored in the global variable on the condition that the line was detected
    
    ```python
    def lanechange_detect(left, center, right):
        global previous_left, previous_cen, previous_right
        global linechange
        if center[2] != 0:
            previous_cen = center
            linechange = True
        elif left[2] != 0 and right[2] != 0:
            previous_left = left
            previous_right = right
            linechange = False
        elif right[2] != 0:
            previous_right = right
        elif left[2] != 0:
            previous_left = left
    ```
    

1. **Select output**
    - It is the most important part of this lab. Since the slope and point is known, I created a function to find the general expression, function to find the x coordinate when y is height and also implemented a function to find the intersection
    - Decide whether to use previous or newly entered data stored in this part and use the determined data to calculate the coordinates to reduce the error
    
    ```python
    #y=mx+b // offset = b
    get_offset = lambda slope, x1, y1: y1-slope*x1
    
    #get x axis if y=height
    def get_x(slope,x1,y1, height):
        b=get_offset(slope, x1, y1)
        if(slope == 0):
            return 0
        x=(height-b)/slope
        return int(x)
    
    def get_intersection(m1, x1, y1, m2, x2, y2):
        b1 = get_offset(m1,x1,y1)
        b2 = get_offset(m2,x2,y2)
        # intersection Point x,y
        return int((b2-b1)/(m1-m2)), int(m1*(b2-b1)/(m1-m2)+b1)
    ```
    
    - If each line was not detected, the value of the declared previous_lane as a global variable was inserted and updated continuously.
    - When there is a line, connects two points where y is height and height/2+50(which is similar to intersection point).
    When there are two lines, each line connects each point where y is height and the intersection of the two lines.
    - The last points variable is the global variable, which is the coordinate for the translucent triangle that will subsequent the output.
    - This is the output image
    
    ![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/select_output.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/select_output.png)
    
    ```python
    def select_output(frame, get_x, get_intersection, left, center, right):
        global previous_left, previous_right, previous_cen, linechange, height
        global tri_color, points, xL, xR, x2, y2
        if linechange:
            # previous
            if center[2] == 0:
                x, y, m = previous_cen
            # now
            else:
                x, y, m = center
            x = get_x(m, x, y, height)
            y = height
            x = get_x(m, x, y, int(height / 2) + 50)
            y = int(height / 2) + 50
            cv.line(frame, (x, y), (x2, y2), (0, 0, 255), 5)
            cv.circle(frame, (x2, y2), 5, (0, 0, 255), 5)
            tri_color = (0, 0, 255)
        else:
            if(left[2] == 0):
                xL, yL, mL = previous_left
                color1 = (0,255,255)
            else:
                xL, yL, mL = left
                color1 = (255,0,0)
            if(right[0] == 0):
                xR, yR, mR = previous_right
                color2 = (0,255,255)
            else:
                xR, yR, mR = right
                color2 = (255,0,0)
            x2, y2 =get_intersection(mL,xL,yL,mR,xR,yR)
            xL = get_x(mL,xL,yL,height)
            xR = get_x(mR,xR,yR,height)
            yR=yL=height
            cv.line(frame, (xL, yL), (x2, y2), color1, 5)
            cv.line(frame, (xR, yR), (x2, y2), color2, 5)
            cv.circle(frame,(x2,y2),5,(0,255,0),5)
            tri_color = (0,255,0)
            points = np.array([[x2,y2],[xL,yL],[xR,yR]])
    ```
    

### Print Output

1. **Bias**
    - Bias is calculated if left and right lanes are detected. Average two x coordinates when y is height and subtract this value by width/2(which is the middle). And divide by width-200(which is the width of the lane)
2. **Lane change direction**
    - Declared a boolean type global variable named way_right
    If the lane is not changing and bias is less than 0, it’s moving to left. Else, it’s moving to right. Store the condition of this state and when linechange variable become True, then direction of lane change will print according to way_right variable.
3. **Translucent triangle**
    - Create an image of a triangle based on the points received from the previous select_output function and use addWeighted function to the original image to show a translucent triangle in the output image
    - This is the output image

![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/put_text.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/put_text.png)

```python
def print_text(frame, xL, xR):
    global linechange, way_right
    global height, width
    bias = (width/2 - (xL+xR)/2)
    bias = (bias/(width-200))*100
    direction =" "
    if(linechange):
        lane_is ="Lane change"
        color =(0,0,255)
        if(bias<0):
            bias=-bias
        if(way_right):
            way = "->"
        else:
            way = "<-"
        cv.putText(frame,way,(int(width/2)-40, int(height/2)),cv.FONT_HERSHEY_SIMPLEX,2,(0,0,255),3)
    else:
        lane_is ="Safe"
        color =(0,255,0)
        if(bias<0):
            direction = "left "
            bias=-bias
            way_right=False
        else:
            direction = "right "
            way_right=True
        #average x of two lines
        cv.line(frame, (int((xL+xR)/2),height-20),(int((xL+xR)/2),height),(204,102,255),5)
    cv.putText(frame, "Bias : "+ direction+f"{bias:.2f}"+" %",(30,50),cv.FONT_HERSHEY_SIMPLEX,1.3,(0,0,0),3)
    cv.putText(frame, "In Line? : "+ lane_is, (30,100),cv.FONT_HERSHEY_SIMPLEX,1.3,color,3)
    cv.line(frame,(int(width/2),height-20),(int(width/2),height),(255,255,255),5)
    return way_right
```

1. **FPS**
    - Declare the time variable, from after reading the file to the end of the code and calculate the fps.
    
    ```cpp
    def cal_fps(frame, start_t, terminate_t):
        FPS = int(1./(terminate_t - start_t ))
        cv.putText(frame, "FPS : "+ str(FPS), (30,150),cv.FONT_HERSHEY_SIMPLEX,1.3,(0,0,0),2)
    ```
    

# Final Result and Analysis

### 1. FInal Result

The exaples of results are shown below, if the car is in the lane or not, the bias, fps, and direction of the lane changing are all well displayed on the screen.

Also it can be seen that the boundary of the lane is also well detected, and the color is colored according to the intention

output example1

![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/output1.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/output1.png)

output example2

![https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/output2.png](https://raw.githubusercontent.com/lcg0070/DLIP/main/lab3/image/output2.png)

**Demo Video  :** [https://www.youtube.com/watch?v=qXyMKnjdfbg&ab_channel=학부생](https://www.youtube.com/watch?v=qXyMKnjdfbg&ab_channel=%ED%95%99%EB%B6%80%EC%83%9D)

### 2. Analysis

The results are very similar to the form shown in the example video, and the bias are also has an error within 20%, so it can be said that the lab was very successful

## Conclusion

The goal of this lab is print warning message from the road lane detection. And also display an approximated rate of the lane departure, and display FPS. 

The results were similar to the example video, but there is someting to improve. That the line is rattling and shaking, resulting in tiny errors. This is because of the logic of outputting based on one of the longest lines, the left and right sides of the single lane are alternately printed.

If we add the logic of outputting the line with the closest coordinate with middle, the calculation time will be slightly increased, but the data will be obtained more stably

# 4. Appendix

### Code

```python
import numpy as np
import cv2 as cv
import timeit as time

#degree to Radian
deg2Rad = lambda d: np.pi/180 * d

#y=mx+b
#get slope->m // if x2=x1 its error, so add very little value    
get_slope = lambda x1, y1, x2, y2: (y2 - y1) / (x2 - x1 + 1e-6)

#get b
get_offset = lambda slope, x1, y1: y1-slope*x1

#get fps
def cal_fps(frame, start_t, terminate_t):
    FPS = int(1./(terminate_t - start_t ))
    cv.putText(frame, "FPS : "+ str(FPS), (30,150),cv.FONT_HERSHEY_SIMPLEX,1.3,(0,0,0),2)

#get x axis if y=height
def get_x(slope,x1,y1, height):
    #y=mx+b
    b=get_offset(slope, x1, y1)
    if(slope == 0):
        return 0
    x=(height-b)/slope
    return int(x)

#get intersection of lines
def get_intersection(m1, x1, y1, m2, x2, y2):
    b1 = get_offset(m1,x1,y1)
    b2 = get_offset(m2,x2,y2)
    # intersection Point x,y
    return int((b2-b1)/(m1-m2)), int(m1*(b2-b1)/(m1-m2)+b1)

#process img
def process_image(img):
    # grayscale
    gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    # gaussianBlur
    blur_img = cv.GaussianBlur(gray_img, (7, 7), 0)
    # canny
    canny_img = cv.Canny(blur_img, 50, 100)
    return canny_img

#HoughLinesP
def hough_roi( processed_img):
    #img size
    height, width = processed_img.shape[:2]
    #triangle ROI
    vertices = np.array([[(0+100, height-70), (width / 2, height / 2+50), (width-100, height-70)]], dtype=np.int32)
    mask = np.zeros_like(processed_img)
    cv.fillPoly(mask, vertices, 255)
    roi_img = cv.bitwise_and(processed_img, mask)
    cv.imshow("what",roi_img)
    #HoughLines
    lines = cv.HoughLinesP(roi_img, 1, np.pi / 180, 50, minLineLength=50, maxLineGap=5)
    return lines

# determine the lines
def cal_lines(lines):
    x_left,x_right,x_center,y_left,y_right,y_center=0,0,0,0,0,0
    max_left, max_right, max_cen= 0,0,0
    slope_right, slope_left, slope_center = 0,0,0
    for line in lines:
        x1, y1, x2, y2 = line[0]
        slope = get_slope(x1, y1, x2, y2)
        if slope < np.tan(deg2Rad(60)) and slope> np.tan(deg2Rad(30)):
            if(abs(y1-y2)>max_right):
                x_right=x1
                y_right=y1
                slope_right = slope
                max_right = abs(y1-y2)
        elif slope < -np.tan(deg2Rad(30)) and slope> -np.tan(deg2Rad(60)):
            if(abs(y1-y2)>max_left):
                x_left=x1
                y_left=y1
                slope_left = slope
                max_left = abs(y1-y2)
        elif abs(slope) >= np.tan(deg2Rad(60)):
            if(abs(y1-y2)>max_cen):
                x_center=x1
                y_center=y1
                slope_center = slope
                max_cen = abs(y1-y2)
        left = [int(x_left),int(y_left),slope_left]
        center = [int(x_center),int(y_center),slope_center]
        right =[int(x_right),int(y_right),slope_right]
    return left, center, right

# determine lanechange
def lanechange_detect(left, center, right):
    global previous_left, previous_cen, previous_right
    global linechange
    if center[2] != 0:
        previous_cen = center
        linechange = True
    elif left[2] != 0 and right[2] != 0:
        previous_left = left
        previous_right = right
        linechange = False
    elif right[2] != 0:
        previous_right = right
    elif left[2] != 0:
        previous_left = left

# previous or not
def select_output(frame, get_x, get_intersection, left, center, right):
    global previous_left, previous_right, previous_cen, linechange, height
    global tri_color, points, xL, xR, x2, y2
    if linechange:
        # previous
        if center[2] == 0:
            x, y, m = previous_cen
        # now
        else:
            x, y, m = center
        x = get_x(m, x, y, height)
        y = height
        x2 = get_x(m, x, y, int(height / 2) + 50)
        y2 = int(height / 2) + 50
        cv.line(frame, (x, y), (x2, y2), (0, 0, 255), 5)
        cv.circle(frame, (x2, y2), 5, (0, 0, 255), 5)
        tri_color = (0, 0, 255)
    else:
        if(left[2] == 0):
            xL, yL, mL = previous_left
            color1 = (0,255,255)
        else:
            xL, yL, mL = left
            color1 = (255,0,0)
        if(right[0] == 0):
            xR, yR, mR = previous_right
            color2 = (0,255,255)
        else:
            xR, yR, mR = right
            color2 = (255,0,0)
        x2, y2 =get_intersection(mL,xL,yL,mR,xR,yR)
        xL = get_x(mL,xL,yL,height)
        xR = get_x(mR,xR,yR,height)
        yR=yL=height
        cv.line(frame, (xL, yL), (x2, y2), color1, 5)
        cv.line(frame, (xR, yR), (x2, y2), color2, 5)
        cv.circle(frame,(x2,y2),5,(0,255,0),5)
        tri_color = (0,255,0)
        points = np.array([[x2,y2],[xL,yL],[xR,yR]])

#put text // direction, bias
def print_text(frame, xL, xR):
    global linechange, way_right
    global height, width
    bias = (width/2 - (xL+xR)/2)
    bias = (bias/(width-200))*100
    direction =" "
    if(linechange):
        lane_is ="Lane change"
        color =(0,0,255)
        if(bias<0):
            bias=-bias
        if(way_right):
            way = "->"
        else:
            way = "<-"
        cv.putText(frame,way,(int(width/2)-40, int(height/2)),cv.FONT_HERSHEY_SIMPLEX,2,(0,0,255),3)
    else:
        lane_is ="Safe"
        color =(0,255,0)
        if(bias<0):
            direction = "left "
            bias=-bias
            way_right=False
        else:
            direction = "right "
            way_right=True
        #average x of two lines
        cv.line(frame, (int((xL+xR)/2),height-20),(int((xL+xR)/2),height),(204,102,255),5)
    cv.putText(frame, "Bias : "+ direction+f"{bias:.2f}"+" %",(30,50),cv.FONT_HERSHEY_SIMPLEX,1.3,(0,0,0),3)
    cv.putText(frame, "In Line? : "+ lane_is, (30,100),cv.FONT_HERSHEY_SIMPLEX,1.3,color,3)
    cv.line(frame,(int(width/2),height-20),(int(width/2),height),(255,255,255),5)
    return way_right

def process_video(cap, lanechange_detect, process_image, hough_roi, cal_lines, print_text):
    global way_right
    global height, width
    if cap.isOpened():
        while True:
            k = cv.waitKey(30)
            start_t = time.default_timer()
            # esc to quit
            ret, frame = cap.read()
            if ret and k != 27:
                # image processing and finding lines
                processed_img = process_image(frame)
                height, width = processed_img.shape[:2]
                lines = hough_roi(processed_img)
                left, center, right = cal_lines(lines)

                # check slope
                lanechange_detect(left, center, right)

                # if slope is not detected 
                select_output(frame, get_x, get_intersection, left, center, right)

                tri_img = np.zeros((height, width, 3), dtype=np.uint8)
                cv.fillPoly(tri_img, [points],tri_color)

                # print bias and lane departure
                way_right =print_text(frame, xL, xR)
            
                cv.imshow('video',frame)
                # calculate FPS
                terminate_t = time.default_timer()
                cal_fps(frame, start_t, terminate_t)

                # add triangle shape 
                result_img = cv.addWeighted(frame, 1, tri_img, 0.3, 0)
                # 이미지를 출력합니다.
                cv.imshow('Lane Detection', result_img)
            else:
                print("end of file")
                break
    else:
        print('cannot open the file')
    cap.release()
    cv.destroyAllWindows()

# main
previous_left = [0, 0, 1e-6]
previous_right = [0, 0, 1e-6]
previous_cen = [0, 0, 1e-6]
height = 0
width = 0
points =[]
xL, xR, x2, y2 = 0,0,0,0
tri_color = (0,0,0)
linechange = False
way_right = False

# cap = cv.VideoCapture('road_straight_student.mp4')
cap = cv.VideoCapture('road_lanechange_student.mp4')

process_video(cap,lanechange_detect, process_image, hough_roi, cal_lines, print_text)
```